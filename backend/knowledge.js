const { DirectoryLoader } = require("langchain/document_loaders/fs/directory");
const { TextLoader } = require("langchain/document_loaders/fs/text");
const { PDFLoader } = require("langchain/document_loaders/fs/pdf");
const { DocxLoader } = require("langchain/document_loaders/fs/docx");
const { OpenAIEmbeddings, ChatOpenAI } = require("@langchain/openai");
const { MemoryVectorStore } = require("langchain/vectorstores/memory");
const { RecursiveCharacterTextSplitter } = require("langchain/text_splitter");
const { createRetrievalChain } = require("langchain/chains/retrieval");
const { createHistoryAwareRetriever } = require("langchain/chains/history_aware_retriever");
const { MessagesPlaceholder } = require("@langchain/core/prompts");
const { ChatPromptTemplate } = require("@langchain/core/prompts");
const { createStuffDocumentsChain } = require("langchain/chains/combine_documents");
const { calculateConfidence } = require('./confidence.js');

let retrievalChain;
let chatHistory = [];
let isRetraining = false;

async function initializeKnowledgeBase() {
  try {
    const loader = new DirectoryLoader(
      "./manuals",
      {
        ".pdf": (path) => new PDFLoader(path, { splitPages: false }),
        ".docx": (path) => new DocxLoader(path),
        ".txt": (path) => new TextLoader(path),
      },
      true // recursive
    );
    const docs = await loader.load();

    if (docs.length === 0) {
      console.log("í•™ìŠµí•  ë¬¸ì„œê°€ manuals í´ë”ì— ì—†ìŠµë‹ˆë‹¤.");
      return;
    }

    const textSplitter = new RecursiveCharacterTextSplitter({ chunkSize: 1000, chunkOverlap: 200 });
    const splitDocs = await textSplitter.splitDocuments(docs);

    const embeddings = new OpenAIEmbeddings({ openAIApiKey: process.env.OPENAI_API_KEY });
    const vectorstore = await MemoryVectorStore.fromDocuments(splitDocs, embeddings);

    const retriever = vectorstore.asRetriever({ k: 4 });
    const llm = new ChatOpenAI({ modelName: "gpt-4o", temperature: 0.1 });

    const historyAwarePrompt = ChatPromptTemplate.fromMessages([
      new MessagesPlaceholder("chat_history"),
      ["user", "{input}"],
      ["user", "Given the above conversation, generate a search query to look up in order to get information relevant to the conversation"],
    ]);

    const historyAwareRetrieverChain = await createHistoryAwareRetriever({
      llm,
      retriever,
      rephrasePrompt: historyAwarePrompt,
    });

    const historyAwareRetrievalPrompt = ChatPromptTemplate.fromMessages([
      ["system", "You are Mr.FILA, an AI assistant for answering questions about FILA ERP. You are a helpful and enthusiastic assistant who is an expert in all things about FILA ERP. Use the following pieces of retrieved context to answer the user's question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise, and answer in Korean.\n\n{context}"],
      new MessagesPlaceholder("chat_history"),
      ["user", "{input}"],
    ]);

    const historyAwareCombineDocsChain = await createStuffDocumentsChain({
      llm,
      prompt: historyAwareRetrievalPrompt,
    });

    retrievalChain = await createRetrievalChain({
      retriever: historyAwareRetrieverChain,
      combineDocsChain: historyAwareCombineDocsChain,
    });

    console.log(`âœ… ${docs.length}ê°œì˜ ë¬¸ì„œë¥¼ í•™ìŠµí•˜ê³  RAG ì²´ì¸ ì´ˆê¸°í™”ë¥¼ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤!`);

  } catch (error) {
    console.error("ğŸš¨ ë¬¸ì„œ í•™ìŠµ ì¤‘ ì—ëŸ¬ ë°œìƒ:", error);
  }
}

async function getAnswer(question) {
  if (!retrievalChain) {
    return {
      answer: "ë¬¸ì„œê°€ ì•„ì§ í•™ìŠµë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. manuals í´ë”ì— ë¬¸ì„œë¥¼ ì¶”ê°€í•˜ê³  ì„œë²„ë¥¼ ì¬ì‹œì‘í•˜ì„¸ìš”.",
      confidence: 0,
      sources: []
    };
  }
  try {
    const response = await retrievalChain.invoke({
      chat_history: chatHistory,
      input: question,
    });
    
    // ì‹ ë¢°ë„ ê³„ì‚°
    const confidence = calculateConfidence(response, question);
    
    // ì†ŒìŠ¤ ë¬¸ì„œ ì •ë³´ ì¶”ì¶œ
    const sources = extractSources(response);
    
    chatHistory.push({ role: 'user', content: question });
    chatHistory.push({ role: 'assistant', content: response.answer });
    // Keep chat history to a reasonable size
    if (chatHistory.length > 10) {
      chatHistory = chatHistory.slice(-10);
    }
    
    return {
      answer: response.answer,
      confidence: confidence,
      sources: sources
    };
  } catch (error) {
    console.error("ğŸš¨ ë‹µë³€ ìƒì„± ì¤‘ ì—ëŸ¬ ë°œìƒ:", error);
    return {
      answer: "ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
      confidence: 0,
      sources: []
    };
  }
}

// ì†ŒìŠ¤ ë¬¸ì„œ ì •ë³´ ì¶”ì¶œ í•¨ìˆ˜
function extractSources(response) {
  if (!response.context || response.context.length === 0) {
    return [];
  }
  
  return response.context.map((doc, index) => ({
    id: index + 1,
    source: doc.metadata?.source || "ì•Œ ìˆ˜ ì—†ëŠ” ì†ŒìŠ¤",
    content: doc.pageContent?.substring(0, 200) + "..." || "",
    relevance: "ê´€ë ¨ ë¬¸ì„œ"
  }));
}

// RAG ì¬í•™ìŠµ í•¨ìˆ˜
async function retrainRAG() {
  if (isRetraining) {
    console.log('ğŸ”„ RAG ì¬í•™ìŠµì´ ì´ë¯¸ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤...');
    return;
  }

  isRetraining = true;
  console.log('ğŸ”„ RAG ì¬í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤...');

  try {
    // ê¸°ì¡´ retrievalChain ì´ˆê¸°í™”
    retrievalChain = null;
    
    // ìƒˆë¡œìš´ ì§€ì‹ ë² ì´ìŠ¤ ì´ˆê¸°í™”
    await initializeKnowledgeBase();
    
    console.log('âœ… RAG ì¬í•™ìŠµì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!');
  } catch (error) {
    console.error('âŒ RAG ì¬í•™ìŠµ ì‹¤íŒ¨:', error);
  } finally {
    isRetraining = false;
  }
}

module.exports = { 
  initializeKnowledgeBase, 
  getAnswer, 
  retrainRAG 
};